{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNOfFtk1RK9DfsCCH+NLpfO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RejaulBSSE1324/text2code-seq2seq/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Efzlidootb_"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install datasets torch torchtext nltk sacrebleu matplotlib seaborn tqdm -q\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import json\n",
        "from datasets import load_dataset\n",
        "from sacrebleu.metrics import BLEU\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "O2bae3espHCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CodeSearchNet dataset\n",
        "print(\"Loading dataset...\")\n",
        "dataset = load_dataset(\"Nan-Do/code-search-net-python\", split=\"train\")\n",
        "\n",
        "# Configuration\n",
        "MAX_SAMPLES = 10000  # Use 10k samples for training\n",
        "MAX_DOC_LEN = 50     # Maximum docstring length\n",
        "MAX_CODE_LEN = 80    # Maximum code length\n",
        "\n",
        "print(f\"Total dataset size: {len(dataset)}\")\n",
        "print(f\"Using {MAX_SAMPLES} samples\")"
      ],
      "metadata": {
        "id": "g_tof7RVpHAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine a sample\n",
        "sample = dataset[0]\n",
        "print(\"Sample docstring:\", sample['docstring'][:200])\n",
        "print(\"\\nSample code:\", sample['code'][:200])"
      ],
      "metadata": {
        "id": "78i6Y22-pG9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary class\n",
        "class Vocabulary:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.word2count = Counter()\n",
        "        self.n_words = 0\n",
        "\n",
        "        # Special tokens\n",
        "        self.PAD_token = 0\n",
        "        self.SOS_token = 1\n",
        "        self.EOS_token = 2\n",
        "        self.UNK_token = 3\n",
        "\n",
        "        self.add_word('<PAD>')\n",
        "        self.add_word('<SOS>')\n",
        "        self.add_word('<EOS>')\n",
        "        self.add_word('<UNK>')\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.word2idx[word] = self.n_words\n",
        "            self.idx2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        self.word2count[word] += 1\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split():\n",
        "            self.add_word(word)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_words"
      ],
      "metadata": {
        "id": "D4xDb1IVpG7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocess_data(dataset, max_samples, max_doc_len, max_code_len):\n",
        "    \"\"\"Preprocess dataset and create vocabularies\"\"\"\n",
        "\n",
        "    processed_data = []\n",
        "    doc_vocab = Vocabulary('docstring')\n",
        "    code_vocab = Vocabulary('code')\n",
        "\n",
        "    for i in tqdm(range(min(max_samples, len(dataset))), desc=\"Processing data\"):\n",
        "        example = dataset[i]\n",
        "\n",
        "        # Get docstring and code\n",
        "        docstring = example['docstring'].strip()\n",
        "        code = example['code'].strip()\n",
        "\n",
        "        # Skip if empty\n",
        "        if not docstring or not code:\n",
        "            continue\n",
        "\n",
        "        # Simple tokenization (whitespace)\n",
        "        doc_tokens = docstring.split()\n",
        "        code_tokens = code.split()\n",
        "\n",
        "        # Skip if too long\n",
        "        if len(doc_tokens) > max_doc_len or len(code_tokens) > max_code_len:\n",
        "            continue\n",
        "\n",
        "        # Skip if too short\n",
        "        if len(doc_tokens) < 3 or len(code_tokens) < 3:\n",
        "            continue\n",
        "\n",
        "        # Add to vocabularies\n",
        "        doc_vocab.add_sentence(docstring)\n",
        "        code_vocab.add_sentence(code)\n",
        "\n",
        "        processed_data.append({\n",
        "            'docstring': docstring,\n",
        "            'code': code\n",
        "        })\n",
        "\n",
        "    print(f\"\\nProcessed {len(processed_data)} valid examples\")\n",
        "    print(f\"Docstring vocabulary size: {len(doc_vocab)}\")\n",
        "    print(f\"Code vocabulary size: {len(code_vocab)}\")\n",
        "\n",
        "    return processed_data, doc_vocab, code_vocab\n",
        "\n",
        "# Process the data\n",
        "processed_data, doc_vocab, code_vocab = preprocess_data(\n",
        "    dataset, MAX_SAMPLES, MAX_DOC_LEN, MAX_CODE_LEN\n",
        ")"
      ],
      "metadata": {
        "id": "Kq--s-PupG46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train/val/test\n",
        "def split_data(data, train_ratio=0.8, val_ratio=0.1):\n",
        "    \"\"\"Split data into train, validation, and test sets\"\"\"\n",
        "    random.shuffle(data)\n",
        "\n",
        "    n = len(data)\n",
        "    train_end = int(n * train_ratio)\n",
        "    val_end = int(n * (train_ratio + val_ratio))\n",
        "\n",
        "    train_data = data[:train_end]\n",
        "    val_data = data[train_end:val_end]\n",
        "    test_data = data[val_end:]\n",
        "\n",
        "    return train_data, val_data, test_data\n",
        "\n",
        "train_data, val_data, test_data = split_data(processed_data)\n",
        "\n",
        "print(f\"Train: {len(train_data)}\")\n",
        "print(f\"Val: {len(val_data)}\")\n",
        "print(f\"Test: {len(test_data)}\")"
      ],
      "metadata": {
        "id": "PcryF-HGpG2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, doc_vocab, code_vocab):\n",
        "        self.data = data\n",
        "        self.doc_vocab = doc_vocab\n",
        "        self.code_vocab = code_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.data[idx]\n",
        "\n",
        "        # Convert to indices\n",
        "        doc_tokens = example['docstring'].split()\n",
        "        code_tokens = example['code'].split()\n",
        "\n",
        "        doc_indices = [self.doc_vocab.word2idx.get(w, self.doc_vocab.UNK_token)\n",
        "                       for w in doc_tokens]\n",
        "        code_indices = [self.code_vocab.SOS_token] + \\\n",
        "                       [self.code_vocab.word2idx.get(w, self.code_vocab.UNK_token)\n",
        "                        for w in code_tokens] + \\\n",
        "                       [self.code_vocab.EOS_token]\n",
        "\n",
        "        return {\n",
        "            'doc': torch.LongTensor(doc_indices),\n",
        "            'code': torch.LongTensor(code_indices),\n",
        "            'doc_text': example['docstring'],\n",
        "            'code_text': example['code']\n",
        "        }\n",
        "\n",
        "# Collate function for batching\n",
        "def collate_fn(batch):\n",
        "    doc_batch = [item['doc'] for item in batch]\n",
        "    code_batch = [item['code'] for item in batch]\n",
        "    doc_texts = [item['doc_text'] for item in batch]\n",
        "    code_texts = [item['code_text'] for item in batch]\n",
        "\n",
        "    # Pad sequences\n",
        "    doc_padded = pad_sequence(doc_batch, batch_first=True, padding_value=0)\n",
        "    code_padded = pad_sequence(code_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Create masks\n",
        "    doc_lengths = torch.LongTensor([len(d) for d in doc_batch])\n",
        "    code_lengths = torch.LongTensor([len(c) for c in code_batch])\n",
        "\n",
        "    return {\n",
        "        'doc': doc_padded,\n",
        "        'code': code_padded,\n",
        "        'doc_lengths': doc_lengths,\n",
        "        'code_lengths': code_lengths,\n",
        "        'doc_texts': doc_texts,\n",
        "        'code_texts': code_texts\n",
        "    }\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CodeDataset(train_data, doc_vocab, code_vocab)\n",
        "val_dataset = CodeDataset(val_data, doc_vocab, code_vocab)\n",
        "test_dataset = CodeDataset(test_data, doc_vocab, code_vocab)\n",
        "\n",
        "# Create dataloaders\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                         shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                       shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                        shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(\"Data loaders created successfully!\")"
      ],
      "metadata": {
        "id": "KzehMnNJpGzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(RNNEncoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        embedded = self.embedding(x)\n",
        "        # Pack padded sequence\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        outputs, hidden = self.rnn(packed)\n",
        "        # Unpack\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "        return outputs, hidden\n",
        "\n",
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(RNNDecoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        output = self.fc(output)\n",
        "        return output, hidden\n",
        "\n",
        "class VanillaSeq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(VanillaSeq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, src_lengths, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        max_len = tgt.size(1)\n",
        "        vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        # Encode\n",
        "        _, hidden = self.encoder(src, src_lengths)\n",
        "\n",
        "        # Decode\n",
        "        outputs = torch.zeros(batch_size, max_len, vocab_size).to(src.device)\n",
        "        input_token = tgt[:, 0].unsqueeze(1)  # Start with SOS\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(input_token, hidden)\n",
        "            outputs[:, t, :] = output.squeeze(1)\n",
        "\n",
        "            # Teacher forcing\n",
        "            use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
        "            if use_teacher_forcing:\n",
        "                input_token = tgt[:, t].unsqueeze(1)\n",
        "            else:\n",
        "                input_token = output.argmax(2)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "print(\"Vanilla RNN Seq2Seq model defined!\")"
      ],
      "metadata": {
        "id": "SXG5BqIFpGux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        embedded = self.embedding(x)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        outputs, (hidden, cell) = self.lstm(packed)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "        return outputs, (hidden, cell)\n",
        "\n",
        "class LSTMDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(LSTMDecoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "        output = self.fc(output)\n",
        "        return output, hidden\n",
        "\n",
        "class LSTMSeq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(LSTMSeq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, src_lengths, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        max_len = tgt.size(1)\n",
        "        vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        # Encode\n",
        "        _, hidden = self.encoder(src, src_lengths)\n",
        "\n",
        "        # Decode\n",
        "        outputs = torch.zeros(batch_size, max_len, vocab_size).to(src.device)\n",
        "        input_token = tgt[:, 0].unsqueeze(1)\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(input_token, hidden)\n",
        "            outputs[:, t, :] = output.squeeze(1)\n",
        "\n",
        "            use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
        "            if use_teacher_forcing:\n",
        "                input_token = tgt[:, t].unsqueeze(1)\n",
        "            else:\n",
        "                input_token = output.argmax(2)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "print(\"LSTM Seq2Seq model defined!\")"
      ],
      "metadata": {
        "id": "UtHYSGjhpGsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BidirectionalLSTMEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(BidirectionalLSTMEncoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc_hidden = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.fc_cell = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        embedded = self.embedding(x)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        outputs, (hidden, cell) = self.lstm(packed)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "\n",
        "        # Combine bidirectional hidden states\n",
        "        hidden = torch.tanh(self.fc_hidden(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))).unsqueeze(0)\n",
        "        cell = torch.tanh(self.fc_cell(torch.cat((cell[-2,:,:], cell[-1,:,:]), dim=1))).unsqueeze(0)\n",
        "\n",
        "        return outputs, (hidden, cell)\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim, encoder_dim):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_dim + encoder_dim, hidden_dim)\n",
        "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs, mask=None):\n",
        "        # hidden: (batch, hidden_dim)\n",
        "        # encoder_outputs: (batch, seq_len, encoder_dim)\n",
        "\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        seq_len = encoder_outputs.size(1)\n",
        "\n",
        "        # Repeat hidden state\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "\n",
        "        # Concatenate and compute energy\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "\n",
        "        # Apply mask if provided\n",
        "        if mask is not None:\n",
        "            attention = attention.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        # Softmax\n",
        "        attention_weights = torch.softmax(attention, dim=1)\n",
        "\n",
        "        # Compute context\n",
        "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
        "\n",
        "        return context, attention_weights\n",
        "\n",
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, encoder_dim):\n",
        "        super(AttentionDecoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.attention = BahdanauAttention(hidden_dim, encoder_dim)\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim + encoder_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden, encoder_outputs, mask=None):\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Get attention context\n",
        "        context, attention_weights = self.attention(\n",
        "            hidden[0].squeeze(0), encoder_outputs, mask\n",
        "        )\n",
        "\n",
        "        # Combine embedding and context\n",
        "        lstm_input = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        # LSTM forward\n",
        "        output, hidden = self.lstm(lstm_input, hidden)\n",
        "\n",
        "        # Prediction\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output, hidden, attention_weights\n",
        "\n",
        "class AttentionSeq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(AttentionSeq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, src_lengths, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        max_len = tgt.size(1)\n",
        "        vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        # Create mask for encoder outputs\n",
        "        mask = torch.zeros(batch_size, src.size(1)).to(src.device)\n",
        "        for i, length in enumerate(src_lengths):\n",
        "            mask[i, :length] = 1\n",
        "\n",
        "        # Encode\n",
        "        encoder_outputs, hidden = self.encoder(src, src_lengths)\n",
        "\n",
        "        # Decode\n",
        "        outputs = torch.zeros(batch_size, max_len, vocab_size).to(src.device)\n",
        "        attentions = torch.zeros(batch_size, max_len, src.size(1)).to(src.device)\n",
        "        input_token = tgt[:, 0].unsqueeze(1)\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden, attention_weights = self.decoder(\n",
        "                input_token, hidden, encoder_outputs, mask\n",
        "            )\n",
        "            outputs[:, t, :] = output.squeeze(1)\n",
        "            attentions[:, t, :] = attention_weights\n",
        "\n",
        "            use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
        "            if use_teacher_forcing:\n",
        "                input_token = tgt[:, t].unsqueeze(1)\n",
        "            else:\n",
        "                input_token = output.argmax(2)\n",
        "\n",
        "        return outputs, attentions\n",
        "\n",
        "print(\"Attention-based LSTM Seq2Seq model defined!\")"
      ],
      "metadata": {
        "id": "hMj2QcC-pGqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, optimizer, criterion, device, clip=1.0, is_attention=False):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        src = batch['doc'].to(device)\n",
        "        tgt = batch['code'].to(device)\n",
        "        src_lengths = batch['doc_lengths']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        if is_attention:\n",
        "            output, _ = model(src, src_lengths, tgt, teacher_forcing_ratio=0.5)\n",
        "        else:\n",
        "            output = model(src, src_lengths, tgt, teacher_forcing_ratio=0.5)\n",
        "\n",
        "        # Calculate loss (ignore first token which is SOS)\n",
        "        output = output[:, 1:].reshape(-1, output.shape[-1])\n",
        "        tgt = tgt[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, tgt)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device, is_attention=False):\n",
        "    \"\"\"Evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
        "            src = batch['doc'].to(device)\n",
        "            tgt = batch['code'].to(device)\n",
        "            src_lengths = batch['doc_lengths']\n",
        "\n",
        "            # Forward pass (no teacher forcing during evaluation)\n",
        "            if is_attention:\n",
        "                output, _ = model(src, src_lengths, tgt, teacher_forcing_ratio=0)\n",
        "            else:\n",
        "                output = model(src, src_lengths, tgt, teacher_forcing_ratio=0)\n",
        "\n",
        "            # Calculate loss\n",
        "            output = output[:, 1:].reshape(-1, output.shape[-1])\n",
        "            tgt = tgt[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, tgt)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion,\n",
        "                n_epochs, device, model_name, is_attention=False):\n",
        "    \"\"\"Complete training loop\"\"\"\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion,\n",
        "                                device, is_attention=is_attention)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device,\n",
        "                          is_attention=is_attention)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), f'{model_name}_best.pt')\n",
        "            print(f\"  --> Saved best model\")\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "print(\"Training functions defined!\")"
      ],
      "metadata": {
        "id": "YZBevDpGpGnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model hyperparameters\n",
        "EMBED_DIM = 256\n",
        "HIDDEN_DIM = 256\n",
        "N_EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "\n",
        "# Store results\n",
        "all_results = {}"
      ],
      "metadata": {
        "id": "hCd1D-uNpGlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Vanilla RNN model\n",
        "rnn_encoder = RNNEncoder(len(doc_vocab), EMBED_DIM, HIDDEN_DIM)\n",
        "rnn_decoder = RNNDecoder(len(code_vocab), EMBED_DIM, HIDDEN_DIM)\n",
        "vanilla_model = VanillaSeq2Seq(rnn_encoder, rnn_decoder).to(device)\n",
        "\n",
        "# Optimizer\n",
        "vanilla_optimizer = optim.Adam(vanilla_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Train\n",
        "vanilla_train_losses, vanilla_val_losses = train_model(\n",
        "    vanilla_model, train_loader, val_loader, vanilla_optimizer, criterion,\n",
        "    N_EPOCHS, device, 'vanilla_rnn', is_attention=False\n",
        ")\n",
        "\n",
        "all_results['Vanilla RNN'] = {\n",
        "    'train_losses': vanilla_train_losses,\n",
        "    'val_losses': vanilla_val_losses,\n",
        "    'model': vanilla_model\n",
        "}"
      ],
      "metadata": {
        "id": "YPS4SVmjpGjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LSTM model\n",
        "lstm_encoder = LSTMEncoder(len(doc_vocab), EMBED_DIM, HIDDEN_DIM)\n",
        "lstm_decoder = LSTMDecoder(len(code_vocab), EMBED_DIM, HIDDEN_DIM)\n",
        "lstm_model = LSTMSeq2Seq(lstm_encoder, lstm_decoder).to(device)\n",
        "\n",
        "# Optimizer\n",
        "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Train\n",
        "lstm_train_losses, lstm_val_losses = train_model(\n",
        "    lstm_model, train_loader, val_loader, lstm_optimizer, criterion,\n",
        "    N_EPOCHS, device, 'lstm', is_attention=False\n",
        ")\n",
        "\n",
        "all_results['LSTM'] = {\n",
        "    'train_losses': lstm_train_losses,\n",
        "    'val_losses': lstm_val_losses,\n",
        "    'model': lstm_model\n",
        "}"
      ],
      "metadata": {
        "id": "qOOOEnOvpGgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Attention model\n",
        "attn_encoder = BidirectionalLSTMEncoder(len(doc_vocab), EMBED_DIM, HIDDEN_DIM)\n",
        "attn_decoder = AttentionDecoder(len(code_vocab), EMBED_DIM, HIDDEN_DIM, HIDDEN_DIM * 2)\n",
        "attn_model = AttentionSeq2Seq(attn_encoder, attn_decoder).to(device)\n",
        "\n",
        "# Optimizer\n",
        "attn_optimizer = optim.Adam(attn_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Train\n",
        "attn_train_losses, attn_val_losses = train_model(\n",
        "    attn_model, train_loader, val_loader, attn_optimizer, criterion,\n",
        "    N_EPOCHS, device, 'lstm_attention', is_attention=True\n",
        ")\n",
        "\n",
        "all_results['LSTM + Attention'] = {\n",
        "    'train_losses': attn_train_losses,\n",
        "    'val_losses': attn_val_losses,\n",
        "    'model': attn_model\n",
        "}"
      ],
      "metadata": {
        "id": "YdJuMLy-pGea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation losses\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Training loss\n",
        "for name, results in all_results.items():\n",
        "    axes[0].plot(results['train_losses'], label=name, marker='o')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training Loss Comparison')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Validation loss\n",
        "for name, results in all_results.items():\n",
        "    axes[1].plot(results['val_losses'], label=name, marker='o')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].set_title('Validation Loss Comparison')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Training curves saved as 'training_curves.png'\")"
      ],
      "metadata": {
        "id": "IYyCyHDopGb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code(model, doc_text, doc_vocab, code_vocab, device, max_len=80, is_attention=False):\n",
        "    \"\"\"Generate code from docstring\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Tokenize input\n",
        "        tokens = doc_text.split()\n",
        "        indices = [doc_vocab.word2idx.get(w, doc_vocab.UNK_token) for w in tokens]\n",
        "        src = torch.LongTensor(indices).unsqueeze(0).to(device)\n",
        "        src_lengths = torch.LongTensor([len(indices)])\n",
        "\n",
        "        # Create initial target (SOS token)\n",
        "        tgt = torch.LongTensor([[code_vocab.SOS_token]]).to(device)\n",
        "\n",
        "        # Encode\n",
        "        if is_attention:\n",
        "            # Create mask\n",
        "            mask = torch.ones(1, src.size(1)).to(device)\n",
        "            encoder_outputs, hidden = model.encoder(src, src_lengths)\n",
        "            attentions = []\n",
        "        else:\n",
        "            _, hidden = model.encoder(src, src_lengths)\n",
        "\n",
        "        # Decode\n",
        "        generated = [code_vocab.SOS_token]\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            input_token = torch.LongTensor([[generated[-1]]]).to(device)\n",
        "\n",
        "            if is_attention:\n",
        "                output, hidden, attn_weights = model.decoder(\n",
        "                    input_token, hidden, encoder_outputs, mask\n",
        "                )\n",
        "                attentions.append(attn_weights.cpu().numpy())\n",
        "            else:\n",
        "                output, hidden = model.decoder(input_token, hidden)\n",
        "\n",
        "            predicted = output.argmax(2).item()\n",
        "            generated.append(predicted)\n",
        "\n",
        "            if predicted == code_vocab.EOS_token:\n",
        "                break\n",
        "\n",
        "        # Convert indices to words\n",
        "        code_tokens = [code_vocab.idx2word[idx] for idx in generated[1:-1]]  # Skip SOS and EOS\n",
        "        code_text = ' '.join(code_tokens)\n",
        "\n",
        "        if is_attention:\n",
        "            return code_text, np.array(attentions).squeeze()\n",
        "        return code_text, None\n",
        "\n",
        "def calculate_bleu(model, dataloader, doc_vocab, code_vocab, device, is_attention=False):\n",
        "    \"\"\"Calculate BLEU score\"\"\"\n",
        "    bleu = BLEU()\n",
        "    references = []\n",
        "    hypotheses = []\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Calculating BLEU\"):\n",
        "        doc_texts = batch['doc_texts']\n",
        "        code_texts = batch['code_texts']\n",
        "\n",
        "        for doc_text, ref_code in zip(doc_texts, code_texts):\n",
        "            generated_code, _ = generate_code(\n",
        "                model, doc_text, doc_vocab, code_vocab, device, is_attention=is_attention\n",
        "            )\n",
        "            references.append([ref_code])\n",
        "            hypotheses.append(generated_code)\n",
        "\n",
        "    score = bleu.corpus_score(hypotheses, references)\n",
        "    return score.score\n",
        "\n",
        "def calculate_exact_match(model, dataloader, doc_vocab, code_vocab, device, is_attention=False):\n",
        "    \"\"\"Calculate exact match accuracy\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Calculating Exact Match\"):\n",
        "        doc_texts = batch['doc_texts']\n",
        "        code_texts = batch['code_texts']\n",
        "\n",
        "        for doc_text, ref_code in zip(doc_texts, code_texts):\n",
        "            generated_code, _ = generate_code(\n",
        "                model, doc_text, doc_vocab, code_vocab, device, is_attention=is_attention\n",
        "            )\n",
        "            if generated_code.strip() == ref_code.strip():\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "print(\"Evaluation functions defined!\")"
      ],
      "metadata": {
        "id": "5iIStS6zpGZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate all models on test set\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION RESULTS ON TEST SET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "evaluation_results = {}\n",
        "\n",
        "for name, results in all_results.items():\n",
        "    print(f\"\\nEvaluating {name}...\")\n",
        "    model = results['model']\n",
        "    is_attention = 'Attention' in name\n",
        "\n",
        "    # Load best model\n",
        "    model_file = name.lower().replace(' + ', '_').replace(' ', '_') + '_best.pt'\n",
        "    model.load_state_dict(torch.load(model_file))\n",
        "\n",
        "    # Calculate metrics\n",
        "    bleu_score = calculate_bleu(model, test_loader, doc_vocab, code_vocab,\n",
        "                                device, is_attention=is_attention)\n",
        "    exact_match = calculate_exact_match(model, test_loader, doc_vocab, code_vocab,\n",
        "                                       device, is_attention=is_attention)\n",
        "\n",
        "    evaluation_results[name] = {\n",
        "        'BLEU': bleu_score,\n",
        "        'Exact Match': exact_match\n",
        "    }\n",
        "\n",
        "    print(f\"  BLEU Score: {bleu_score:.2f}\")\n",
        "    print(f\"  Exact Match: {exact_match:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "id": "3f-zaudppGVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create comparison table\n",
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame(evaluation_results).T\n",
        "print(\"\\nComparison Table:\")\n",
        "print(results_df.to_string())\n",
        "\n",
        "# Visualize results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# BLEU scores\n",
        "models = list(evaluation_results.keys())\n",
        "bleu_scores = [evaluation_results[m]['BLEU'] for m in models]\n",
        "axes[0].bar(models, bleu_scores, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
        "axes[0].set_ylabel('BLEU Score')\n",
        "axes[0].set_title('BLEU Score Comparison')\n",
        "axes[0].set_ylim([0, max(bleu_scores) * 1.2])\n",
        "for i, v in enumerate(bleu_scores):\n",
        "    axes[0].text(i, v + 0.5, f\"{v:.2f}\", ha='center', fontweight='bold')\n",
        "\n",
        "# Exact match\n",
        "exact_matches = [evaluation_results[m]['Exact Match'] for m in models]\n",
        "axes[1].bar(models, exact_matches, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
        "axes[1].set_ylabel('Exact Match (%)')\n",
        "axes[1].set_title('Exact Match Accuracy Comparison')\n",
        "axes[1].set_ylim([0, max(exact_matches) * 1.2 if max(exact_matches) > 0 else 10])\n",
        "for i, v in enumerate(exact_matches):\n",
        "    axes[1].text(i, v + 0.5, f\"{v:.2f}%\", ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('evaluation_metrics.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nEvaluation metrics chart saved as 'evaluation_metrics.png'\")"
      ],
      "metadata": {
        "id": "LSIJ6AmJpGNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate samples from test set\n",
        "def show_sample_generations(models_dict, test_data, doc_vocab, code_vocab, device, n_samples=5):\n",
        "    \"\"\"Show sample generations from all models\"\"\"\n",
        "\n",
        "    samples = random.sample(test_data, n_samples)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"SAMPLE {i+1}\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"\\nDocstring: {sample['docstring']}\")\n",
        "        print(f\"\\nReference Code: {sample['code']}\")\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "\n",
        "        for model_name, results in models_dict.items():\n",
        "            model = results['model']\n",
        "            is_attention = 'Attention' in model_name\n",
        "\n",
        "            generated, _ = generate_code(\n",
        "                model, sample['docstring'], doc_vocab, code_vocab,\n",
        "                device, is_attention=is_attention\n",
        "            )\n",
        "\n",
        "            print(f\"\\n{model_name}:\")\n",
        "            print(f\"  {generated}\")\n",
        "\n",
        "        print()\n",
        "\n",
        "# Show sample generations\n",
        "show_sample_generations(all_results, test_data, doc_vocab, code_vocab, device, n_samples=5)"
      ],
      "metadata": {
        "id": "KjOjxkZ0p1Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_attention(doc_text, generated_code, attention_weights,\n",
        "                       doc_vocab, code_vocab, save_path=None):\n",
        "    \"\"\"Visualize attention heatmap\"\"\"\n",
        "\n",
        "    # Get tokens\n",
        "    doc_tokens = doc_text.split()\n",
        "    code_tokens = generated_code.split()\n",
        "\n",
        "    # Trim attention to match generated length\n",
        "    attention_weights = attention_weights[:len(code_tokens), :len(doc_tokens)]\n",
        "\n",
        "    # Create heatmap\n",
        "    fig, ax = plt.subplots(figsize=(max(10, len(doc_tokens) * 0.5),\n",
        "                                    max(8, len(code_tokens) * 0.4)))\n",
        "\n",
        "    sns.heatmap(attention_weights,\n",
        "                xticklabels=doc_tokens,\n",
        "                yticklabels=code_tokens,\n",
        "                cmap='YlOrRd',\n",
        "                ax=ax,\n",
        "                cbar_kws={'label': 'Attention Weight'})\n",
        "\n",
        "    ax.set_xlabel('Docstring Tokens', fontsize=12)\n",
        "    ax.set_ylabel('Generated Code Tokens', fontsize=12)\n",
        "    ax.set_title('Attention Alignment Heatmap', fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Generate attention visualizations\n",
        "print(\"Generating attention visualizations...\\n\")\n",
        "\n",
        "# Get attention model\n",
        "attn_model = all_results['LSTM + Attention']['model']\n",
        "attn_model.load_state_dict(torch.load('lstm_attention_best.pt'))\n",
        "\n",
        "# Select interesting test examples\n",
        "visualization_samples = random.sample(test_data, 3)\n",
        "\n",
        "for i, sample in enumerate(visualization_samples):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"Docstring: {sample['docstring']}\")\n",
        "    print(f\"Reference: {sample['code']}\")\n",
        "\n",
        "    # Generate with attention\n",
        "    generated_code, attention_weights = generate_code(\n",
        "        attn_model, sample['docstring'], doc_vocab, code_vocab,\n",
        "        device, is_attention=True\n",
        "    )\n",
        "\n",
        "    print(f\"Generated: {generated_code}\")\n",
        "\n",
        "    # Visualize\n",
        "    if attention_weights is not None and len(attention_weights) > 0:\n",
        "        visualize_attention(\n",
        "            sample['docstring'], generated_code, attention_weights,\n",
        "            doc_vocab, code_vocab,\n",
        "            save_path=f'attention_heatmap_{i+1}.png'\n",
        "        )\n",
        "        print(f\"Saved attention heatmap as 'attention_heatmap_{i+1}.png'\")\n",
        "    print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "id": "HaORRfpep1Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_length_performance(model, test_data, doc_vocab, code_vocab, device,\n",
        "                              is_attention=False, model_name=\"Model\"):\n",
        "    \"\"\"Analyze performance vs docstring length\"\"\"\n",
        "\n",
        "    # Group by length\n",
        "    length_buckets = {}\n",
        "\n",
        "    for sample in tqdm(test_data[:200], desc=f\"Analyzing {model_name}\"):  # Use subset for speed\n",
        "        doc_len = len(sample['docstring'].split())\n",
        "        bucket = (doc_len // 10) * 10  # Group by 10s\n",
        "\n",
        "        if bucket not in length_buckets:\n",
        "            length_buckets[bucket] = {'correct': 0, 'total': 0}\n",
        "\n",
        "        generated, _ = generate_code(\n",
        "            model, sample['docstring'], doc_vocab, code_vocab,\n",
        "            device, is_attention=is_attention\n",
        "        )\n",
        "\n",
        "        # Check if correct\n",
        "        if generated.strip() == sample['code'].strip():\n",
        "            length_buckets[bucket]['correct'] += 1\n",
        "        length_buckets[bucket]['total'] += 1\n",
        "\n",
        "    # Calculate accuracy per bucket\n",
        "    lengths = sorted(length_buckets.keys())\n",
        "    accuracies = []\n",
        "\n",
        "    for length in lengths:\n",
        "        bucket = length_buckets[length]\n",
        "        acc = 100.0 * bucket['correct'] / bucket['total'] if bucket['total'] > 0 else 0\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    return lengths, accuracies\n",
        "\n",
        "# Analyze all models\n",
        "print(\"Analyzing performance vs docstring length...\\n\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for name, results in all_results.items():\n",
        "    model = results['model']\n",
        "    is_attention = 'Attention' in name\n",
        "\n",
        "    # Load best model\n",
        "    model_file = name.lower().replace(' + ', '_').replace(' ', '_') + '_best.pt'\n",
        "    model.load_state_dict(torch.load(model_file))\n",
        "\n",
        "    lengths, accuracies = analyze_length_performance(\n",
        "        model, test_data, doc_vocab, code_vocab, device,\n",
        "        is_attention=is_attention, model_name=name\n",
        "    )\n",
        "\n",
        "    plt.plot(lengths, accuracies, marker='o', label=name, linewidth=2)\n",
        "\n",
        "plt.xlabel('Docstring Length (tokens)', fontsize=12)\n",
        "plt.ylabel('Exact Match Accuracy (%)', fontsize=12)\n",
        "plt.title('Performance vs Docstring Length', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('length_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nLength analysis saved as 'length_analysis.png'\")"
      ],
      "metadata": {
        "id": "hWwnX_tfp6kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF FINDINGS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. TRAINING PERFORMANCE:\")\n",
        "for name, results in all_results.items():\n",
        "    final_train_loss = results['train_losses'][-1]\n",
        "    final_val_loss = results['val_losses'][-1]\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Final Training Loss: {final_train_loss:.4f}\")\n",
        "    print(f\"  Final Validation Loss: {final_val_loss:.4f}\")\n",
        "\n",
        "print(\"\\n\\n2. TEST SET METRICS:\")\n",
        "print(results_df.to_string())\n",
        "\n",
        "print(\"\\n\\n3. KEY OBSERVATIONS:\")\n",
        "print(\"\\n- Vanilla RNN: \")\n",
        "print(\"  Suffers from vanishing gradients, struggles with longer sequences\")\n",
        "print(\"\\n- LSTM: \")\n",
        "print(\"  Better at capturing long-range dependencies, improved performance\")\n",
        "print(\"\\n- LSTM + Attention: \")\n",
        "print(\"  Removes fixed-context bottleneck, best overall performance\")\n",
        "print(\"  Attention weights show semantic alignment between docstring and code\")\n",
        "\n",
        "print(\"\\n\\n4. DELIVERABLES GENERATED:\")\n",
        "print(\"   training_curves.png - Training/validation loss comparison\")\n",
        "print(\"   evaluation_metrics.png - BLEU and Exact Match comparison\")\n",
        "print(\"   attention_heatmap_1.png, 2.png, 3.png - Attention visualizations\")\n",
        "print(\"   length_analysis.png - Performance vs docstring length\")\n",
        "print(\"   vanilla_rnn_best.pt, lstm_best.pt, lstm_attention_best.pt - Saved models\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Assignment Complete!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "tzJ8z5zvp6fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all results to JSON for easy report generation\n",
        "import json\n",
        "\n",
        "report_data = {\n",
        "    'training_config': {\n",
        "        'embedding_dim': EMBED_DIM,\n",
        "        'hidden_dim': HIDDEN_DIM,\n",
        "        'n_epochs': N_EPOCHS,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'train_samples': len(train_data),\n",
        "        'val_samples': len(val_data),\n",
        "        'test_samples': len(test_data)\n",
        "    },\n",
        "    'results': {}\n",
        "}\n",
        "\n",
        "for name, results in all_results.items():\n",
        "    report_data['results'][name] = {\n",
        "        'train_losses': results['train_losses'],\n",
        "        'val_losses': results['val_losses'],\n",
        "        'final_train_loss': results['train_losses'][-1],\n",
        "        'final_val_loss': results['val_losses'][-1],\n",
        "        'bleu_score': evaluation_results[name]['BLEU'],\n",
        "        'exact_match': evaluation_results[name]['Exact Match']\n",
        "    }\n",
        "\n",
        "with open('experiment_results.json', 'w') as f:\n",
        "    json.dump(report_data, f, indent=2)\n",
        "\n",
        "print(\"Results saved to 'experiment_results.json'\")\n",
        "print(\"\\nAll files ready for your report!\")"
      ],
      "metadata": {
        "id": "mi9j5kZYp6aa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}